---
layout: home
title: Home
---

<div class="social-links" markdown="1">
[github](https://github.com/vishar0) \| [linkedin](https://linkedin.com/in/vishar0) \| [resume](/assets/resume.pdf) \| [twitter](https://twitter.com/viswanathgs) \| [scholar](https://scholar.google.com/citations?user=hLPvq9AAAAAJ) \| [email](mailto:viswanathgs@gmail.com)
</div>

I'm an AI research scientist and an engineer. I'm currently building something new and ambitious with an incredible team.

Previously, I was at Meta for 13 years. From 2020-2025, I was a research lead in the Neural Interfaces Group at Reality Labs pioneering human-AI input using [wrist electromyography](https://www.meta.com/emerging-tech/emg-wearable-technology) (EMG), with a specific focus on text/language decoding. My work culminated in the launch of the [Neural Band](https://www.meta.com/ai-glasses/meta-ray-ban-display-glasses-and-neural-band/), the first general-purpose consumer neural interface product, [demonstrated live](https://www.youtube.com/live/D97ILdUbYww?si=ClCg_DACoSjyMT4g&t=3134) by Mark Zuckerberg at Connect 2025. Some of our underlying research has been published in [Nature](https://www.nature.com/articles/s41586-025-09255-w) and [NeurIPS](https://ai.meta.com/blog/open-sourcing-surface-electromyography-datasets-neurips-2024). Prior to neural interfaces, I worked on [vision](https://arxiv.org/abs/1910.05085), [reinforcement learning](https://arxiv.org/abs/1910.04054), and [ML systems](https://arxiv.org/abs/1811.09886) at Meta AI (FAIR).

I have had the good fortune of getting to experience living in SF, NYC, and London during my 20s. I currently live in NYC.
